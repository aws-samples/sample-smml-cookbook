{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2\n",
    "## Lab 2: Back to Libraries\n",
    "\n",
    "Now that we understand HOW sharding is done, we can understand how this tool is utilized by  libaries to optimize your model inference/training across multiple accelerators. If you want a deeper dive on individual sharding patterns that make up parallism patterns, and the collectives associated with them, we highly recommend [this chapter](https://jax-ml.github.io/scaling-book/sharding/) of **How to Scale your Model**.\n",
    "\n",
    "In this notebook though, we will focus on the different parallism strategies that can be implemented by these libaries, and what the considerations with them are.\n",
    "\n",
    "### Parallism Patterns\n",
    "This lab will be a hands on representation of common parallism patterns. If you want a achemic deep dive, we suggest you read through [The Ultra-Scale Playbook](https://huggingface.co/spaces/nanotron/ultrascale-playbook?section=high_level_overview).\n",
    "\n",
    "> Note we will be using Deepspeed here but this could just as easily be done with any distributed inference/training framework, they have similar interfaces\n",
    "\n",
    "We will be covering the following:\n",
    "- Data Parallism\n",
    "- Tensor Parallism (Like we covered last chapter)\n",
    "- Pipeline Parallism\n",
    "- ZeRO-3/FSDP (these can be interchangable in most contexts)\n",
    "\n",
    "There are other strategies as well, and likely more will emerge, but these are the main ones and others will follow similar concepts. Throughout the first part of this module we'll still be using a small model to demonstrate different types of parallism. At the end we will combine these strategies to run a much larger model on the same instance!\n",
    "\n",
    "The concepts we cover in this module can scale to thousands of GPUs.\n",
    "\n",
    "Let's start by installing our libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/ec2-user/.local/lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/.local/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: deepspeed in /home/ec2-user/.local/lib/python3.12/site-packages (0.16.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/.local/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/.local/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: einops in /home/ec2-user/.local/lib/python3.12/site-packages (from deepspeed) (0.8.1)\n",
      "Requirement already satisfied: hjson in /home/ec2-user/.local/lib/python3.12/site-packages (from deepspeed) (3.1.0)\n",
      "Requirement already satisfied: msgpack in /home/ec2-user/.local/lib/python3.12/site-packages (from deepspeed) (1.1.0)\n",
      "Requirement already satisfied: ninja in /home/ec2-user/.local/lib/python3.12/site-packages (from deepspeed) (1.11.1.4)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ec2-user/.local/lib/python3.12/site-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from deepspeed) (2.11.4)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/ec2-user/.local/lib/python3.12/site-packages (from deepspeed) (12.570.86)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ec2-user/.local/lib/python3.12/site-packages (from pydantic>=2.0.0->deepspeed) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from pydantic>=2.0.0->deepspeed) (0.4.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (80.7.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/.local/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/.local/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/.local/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate deepspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run through the different types of parallism. Keep an eye out for `OUTPUT BREAKDOWN` to see what the token generation and cost looks like. You may see some warnings/errors but these are benign and can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "Before we get started we'll provide an appendix that describes the different images we'll be going through to visualize the types of parallism, their advantages and disadvantages.\n",
    "\n",
    "![](./assets/appendix.png)\n",
    "\n",
    "- The A Matrix represents data being input, as well as it's sequence length and batch size depending on how large it is\n",
    "- The B matrix represents the parameters for the model\n",
    "- The training states represent addition memory needed for forward/backward pass in training, in inference this isn't relevant, and you essentially only have the forward pass\n",
    "- We will be using GPUs but this could work with Neuron devices or any other accelerator\n",
    "- We won't be using 2x2 topologies, but in reality, that's how you'd model out your GPU topology when using multiple types of parallism\n",
    "\n",
    "With that out of the way let's jump into data parallism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Parallel\n",
    "![](./assets/dp.png)\n",
    "**How it works:**\n",
    "Each GPU has a full copy of the model. Batches are split across GPUs. Gradients are synced after the backward pass. As you can see this affectively just splits the input data. If your model is too large, or the training states take up too much memory this won't help reduce your memory footprint. It's best used as a tool to improve throughput.\n",
    "\n",
    "âœ… Advantages:\n",
    "- Easy to implement (e.g., torch.nn.DataParallel, DDP)\n",
    "- Scales well for small to mid-sized models\n",
    "- No model code changes required\n",
    "- Best for large data sets and small models\n",
    "\n",
    "âŒ Disadvantages:\n",
    "- Inefficient for very large models (can't fit on one GPU)\n",
    "- All-reduce on gradients becomes a bottleneck at high scale\n",
    "\n",
    "\n",
    "Let's see it in action. We'll use a smaller model (1B) because we aren't splitting the model this time.\n",
    "\n",
    "> Note: Deepspeed does this automatically as you provide basic optimization and multiple GPUs, as it's a standard optimization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-21 20:24:34,386] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-21 20:24:34,409] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-21 20:24:36,075] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-21 20:24:36,075] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-05-21 20:24:36,172] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-21 20:24:36,636] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2\n",
      "[2025-05-21 20:24:36,757] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.2, git-hash=unknown, git-branch=unknown\n",
      "[2025-05-21 20:24:36,757] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized\n",
      "[2025-05-21 20:24:36,757] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2\n",
      "[2025-05-21 20:24:36,991] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "ninja: no work to do.\n",
      "Time to load fused_adam op: 0.04028892517089844 seconds\n",
      "Time to load fused_adam op: 0.10103178024291992 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ec2-user/.cache/torch_extensions/py312_cu124 as PyTorch extensions root...\n",
      "Using /home/ec2-user/.cache/torch_extensions/py312_cu124 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ec2-user/.cache/torch_extensions/py312_cu124/fused_adam/build.ninja...\n",
      "/home/ec2-user/.local/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-21 20:24:37,521] [INFO] [logging.py:128:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2025-05-21 20:24:37,521] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-05-21 20:24:37,523] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2025-05-21 20:24:37,523] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
      "[2025-05-21 20:24:37,523] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
      "[2025-05-21 20:24:37,523] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
      "[2025-05-21 20:24:37,523] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
      "[2025-05-21 20:24:37,523] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2025-05-21 20:24:37,523] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2025-05-21 20:24:39,524] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
      "[2025-05-21 20:24:39,524] [INFO] [utils.py:782:see_memory_usage] MA 4.61 GB         Max_MA 5.76 GB         CA 5.76 GB         Max_CA 6 GB \n",
      "[2025-05-21 20:24:39,524] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 6.93 GB, percent = 3.8%\n",
      "[2025-05-21 20:24:39,635] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
      "[2025-05-21 20:24:39,653] [INFO] [utils.py:782:see_memory_usage] MA 4.61 GB         Max_MA 6.91 GB         CA 8.06 GB         Max_CA 8 GB \n",
      "[2025-05-21 20:24:39,653] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 6.75 GB, percent = 3.7%\n",
      "[2025-05-21 20:24:39,653] [INFO] [stage_1_and_2.py:544:__init__] optimizer state initialized\n",
      "[2025-05-21 20:24:39,759] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2025-05-21 20:24:39,759] [INFO] [utils.py:782:see_memory_usage] MA 4.61 GB         Max_MA 4.61 GB         CA 8.06 GB         Max_CA 8 GB \n",
      "[2025-05-21 20:24:39,759] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 6.76 GB, percent = 3.7%\n",
      "[2025-05-21 20:24:39,760] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\n",
      "[2025-05-21 20:24:39,761] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None\n",
      "[2025-05-21 20:24:39,761] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2025-05-21 20:24:39,761] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[3e-05], mom=[[0.9, 0.999]]\n",
      "[2025-05-21 20:24:39,761] [INFO] [config.py:999:print] DeepSpeedEngine configuration:\n",
      "[2025-05-21 20:24:39,761] [INFO] [config.py:1003:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2025-05-21 20:24:39,761] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n",
      "[2025-05-21 20:24:39,761] [INFO] [config.py:1003:print]   amp_enabled .................. False\n",
      "[2025-05-21 20:24:39,761] [INFO] [config.py:1003:print]   amp_params ................... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   bfloat16_enabled ............. False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb56b32b380>\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   communication_data_type ...... None\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   disable_allgather ............ False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   dump_state ................... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   elasticity_enabled ........... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   fp16_auto_cast ............... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   fp16_enabled ................. True\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   global_rank .................. 0\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   gradient_clipping ............ 0.0\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   graph_harvesting ............. False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 65536\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   loss_scale ................... 0\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   memory_breakdown ............. False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False\n",
      "[2025-05-21 20:24:39,762] [INFO] [config.py:1003:print]   mics_shard_size .............. -1\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   optimizer_name ............... adamw\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   optimizer_params ............. {'lr': 3e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.01}\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   pld_enabled .................. False\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   pld_params ................... False\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   prescale_gradients ........... False\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   scheduler_name ............... None\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   scheduler_params ............. None\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   sparse_attention ............. None\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   steps_per_print .............. None\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   train_batch_size ............. 2\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   use_node_local_storage ....... False\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   weight_quantization_config ... None\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   world_size ................... 2\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   zero_enabled ................. True\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 1\n",
      "[2025-05-21 20:24:39,763] [INFO] [config.py:989:print_user_config]   json = {\n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 3e-05, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.01\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 1\n",
      "    }, \n",
      "    \"replace_with_kernel_inject\": false, \n",
      "    \"enable_cuda_graph\": false\n",
      "}\n",
      "[Rank 1] input_ids.shape: torch.Size([1, 23])\n",
      "[Rank 1] Allocated: 4.95 GB\n",
      "[Rank 1] Reserved:  8.66 GB\n",
      "\n",
      "ðŸ” Running batch size = 1\n",
      "[Rank 0] input_ids.shape: torch.Size([1, 21])\n",
      "[Rank 0] Allocated: 4.95 GB\n",
      "[Rank 0] Reserved:  8.66 GB\n",
      "[2025-05-21 20:24:41,331] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "[2025-05-21 20:24:42,271] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch=1 | SeqLen=32\n",
      "Elapsed GPU time: 0.2025s | TFLOP/s: 3.9 | AI: 22.86 FLOP/B\n",
      "Batch=1 | SeqLen=32\n",
      "Elapsed GPU time: 0.2030s | TFLOP/s: 3.9 | AI: 22.86 FLOP/B\n",
      "--------- OUTPUT BREAKDOWN ---------\n",
      "ðŸ§  Tokens generated: 64\n",
      "âš¡ Throughput: 315.70004 tokens/sec\n",
      "â±ï¸ Total time: 0.20272 sec\n",
      "ðŸ’¸ Cost per 1M tokens: $1.06465\n",
      "------------------------------------\n",
      "âœ… Distributed env torn down and memory cleared.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import torch\n",
    "import src.utils.model_utils as mutils\n",
    "importlib.reload(mutils)\n",
    "\n",
    "# Create a temporary deepspeed config file\n",
    "ds_config = {\n",
    "    \"train_micro_batch_size_per_gpu\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "\n",
    "    \"fp16\": { \"enabled\": True },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 3e-5,\n",
    "            \"betas\": [0.9, 0.999],\n",
    "            \"eps\": 1e-8,\n",
    "            \"weight_decay\": 0.01\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1\n",
    "    },\n",
    "\n",
    "    \"replace_with_kernel_inject\": False,\n",
    "    \"enable_cuda_graph\": False\n",
    "}\n",
    "results = mutils.run_distributed_benchmark(\n",
    "    model_name=\"NousResearch/Llama-3.2-1B\",\n",
    "    seq_len=8,\n",
    "    batch_sizes=[1],\n",
    "    dtype=torch.bfloat16,\n",
    "    sharding=True,\n",
    "    world_size=1, # Number of GPUs\n",
    "    ds_config=ds_config\n",
    ")\n",
    "\n",
    "\n",
    "results = mutils.run_distributed_benchmark(\n",
    "    model_name=\"NousResearch/Llama-3.2-1B\",\n",
    "    seq_len=32,\n",
    "    batch_sizes=[1],\n",
    "    dtype=torch.bfloat16,\n",
    "    sharding=True,\n",
    "    world_size=2, # Number of GPUs\n",
    "    ds_config=ds_config\n",
    ")\n",
    "mutils.reset_distributed_and_clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! As you can see distributed data can allow us to process our workload much faster, this is similar to how we previously used batching to improove price/performance. Here we can do something similar. But once our model is large enough this stragegy will no longer work, and we'll run into the same issues as before. So we'll have to find ways to either reduce the model size or reduce the training states (in most cases both)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZeRO-3/FSDP\n",
    "![](./assets/zero.png)\n",
    "**How it works:**\n",
    "ZeRO-3 (and FSDP) shards all model states â€” including parameters, gradients, and optimizer states â€” across GPUs. It avoids redundancy by ensuring that no GPU holds a full copy of the model. Parameters are temporarily reconstructed using AllGather at compute time.\n",
    "\n",
    "âœ… Advantages:\n",
    "- Shards the entire model, including non-linear layers, embeddings, and optimizer states\n",
    "- Enables training models that exceed per-GPU memory\n",
    "- Integrates with existing PyTorch models via FSDP or DeepSpeed ZeRO\n",
    "\n",
    "âŒ Disadvantages:\n",
    "- Requires full parameter AllGather before each forward/backward step\n",
    "- Communication-intensive (especially with many GPUs)\n",
    "- Can be slower without high-bandwidth interconnect (e.g., NVLink or InfiniBand)\n",
    "\n",
    "> We will often stack ZeRO-3/FSDP with other strategies like Tensor and Data Parallelism. For example, we may shard linear layers with TP while still using ZeRO-3 to handle the remaining memory overhead from unsharded layers and optimizer state. This allows us to scale across both memory and compute bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-21 20:35:33,222] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-21 20:35:33,246] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-21 20:35:34,919] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-21 20:35:34,920] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-05-21 20:35:35,051] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-21 20:35:35,515] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2\n",
      "[2025-05-21 20:35:35,624] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.2, git-hash=unknown, git-branch=unknown\n",
      "[2025-05-21 20:35:35,624] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized\n",
      "[2025-05-21 20:35:35,624] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2\n",
      "[2025-05-21 20:35:35,860] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2025-05-21 20:35:37,005] [WARNING] [cpu_adam.py:84:__init__] FP16 params for CPUAdam may not work on AMD CPUs\n",
      "[2025-05-21 20:35:37,005] [WARNING] [cpu_adam.py:84:__init__] FP16 params for CPUAdam may not work on AMD CPUs\n",
      "Installed CUDA version 12.6 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination\n",
      "Installed CUDA version 12.6 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination\n",
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 2.2964656352996826 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000030, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2025-05-21 20:35:39,307] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2\n",
      "Time to load cpu_adam op: 2.380248546600342 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000030, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2025-05-21 20:35:39,386] [INFO] [logging.py:128:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2025-05-21 20:35:39,386] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-05-21 20:35:39,388] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2025-05-21 20:35:39,388] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2025-05-21 20:35:39,389] [INFO] [logging.py:128:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2025-05-21 20:35:39,389] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ec2-user/.cache/torch_extensions/py312_cu124 as PyTorch extensions root...\n",
      "Using /home/ec2-user/.cache/torch_extensions/py312_cu124 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ec2-user/.cache/torch_extensions/py312_cu124/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module cpu_adam...\n",
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-21 20:35:39,511] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning\n",
      "[2025-05-21 20:35:39,511] [INFO] [utils.py:782:see_memory_usage] MA 2.3 GB         Max_MA 2.79 GB         CA 2.79 GB         Max_CA 3 GB \n",
      "[2025-05-21 20:35:39,512] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 6.62 GB, percent = 3.6%\n",
      "[2025-05-21 20:35:39,512] [INFO] [stage3.py:168:__init__] Reduce bucket size 500000000\n",
      "[2025-05-21 20:35:39,512] [INFO] [stage3.py:169:__init__] Prefetch bucket size 50000000\n",
      "[2025-05-21 20:35:39,620] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2025-05-21 20:35:39,620] [INFO] [utils.py:782:see_memory_usage] MA 2.3 GB         Max_MA 2.3 GB         CA 2.79 GB         Max_CA 3 GB \n",
      "[2025-05-21 20:35:39,620] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 6.62 GB, percent = 3.6%\n",
      "[2025-05-21 20:35:39,622] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2\n",
      "Parameter Offload: Total persistent parameters: 67584 in 33 params\n",
      "[2025-05-21 20:35:40,620] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2025-05-21 20:35:40,621] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 2.3 GB         CA 2.79 GB         Max_CA 3 GB \n",
      "[2025-05-21 20:35:40,621] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 9.13 GB, percent = 5.0%\n",
      "[2025-05-21 20:35:40,733] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions\n",
      "[2025-05-21 20:35:40,734] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 2.79 GB         Max_CA 3 GB \n",
      "[2025-05-21 20:35:40,734] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 9.13 GB, percent = 5.0%\n",
      "[2025-05-21 20:35:42,076] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 1\n",
      "[2025-05-21 20:35:42,077] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 2.79 GB         Max_CA 3 GB \n",
      "[2025-05-21 20:35:42,077] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 15.59 GB, percent = 8.6%\n",
      "[2025-05-21 20:35:42,193] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions\n",
      "[2025-05-21 20:35:42,194] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 2.79 GB         Max_CA 3 GB \n",
      "[2025-05-21 20:35:42,194] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 15.49 GB, percent = 8.5%\n",
      "[2025-05-21 20:35:42,525] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions\n",
      "[2025-05-21 20:35:42,526] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 2.79 GB         Max_CA 3 GB \n",
      "[2025-05-21 20:35:42,526] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 17.77 GB, percent = 9.8%\n",
      "[2025-05-21 20:35:42,725] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
      "[2025-05-21 20:35:42,725] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 2.79 GB         Max_CA 3 GB \n",
      "[2025-05-21 20:35:42,725] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 22.47 GB, percent = 12.4%\n",
      "[2025-05-21 20:35:45,496] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
      "[2025-05-21 20:35:45,497] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 2.79 GB         Max_CA 3 GB \n",
      "[2025-05-21 20:35:45,497] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.93 GB, percent = 14.3%\n",
      "[2025-05-21 20:35:45,498] [INFO] [stage3.py:528:_setup_for_real_optimizer] optimizer state initialized\n",
      "[2025-05-21 20:35:47,672] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2025-05-21 20:35:47,673] [INFO] [utils.py:782:see_memory_usage] MA 0.93 GB         Max_MA 1.91 GB         CA 3.73 GB         Max_CA 4 GB \n",
      "[2025-05-21 20:35:47,673] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 31.12 GB, percent = 17.1%\n",
      "[2025-05-21 20:35:47,673] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3\n",
      "[2025-05-21 20:35:47,673] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None\n",
      "[2025-05-21 20:35:47,673] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2025-05-21 20:35:47,673] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[3e-05], mom=[[0.9, 0.999]]\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:999:print] DeepSpeedEngine configuration:\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   amp_enabled .................. False\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   amp_params ................... False\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   bfloat16_enabled ............. False\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True\n",
      "[2025-05-21 20:35:47,674] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7f30cd2780>\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   communication_data_type ...... None\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   disable_allgather ............ False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   dump_state ................... False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   elasticity_enabled ........... False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   fp16_auto_cast ............... False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   fp16_enabled ................. True\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   global_rank .................. 0\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   gradient_clipping ............ 0.0\n",
      "[2025-05-21 20:35:47,675] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   graph_harvesting ............. False\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 65536\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   loss_scale ................... 0\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   memory_breakdown ............. False\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   mics_shard_size .............. -1\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   optimizer_name ............... adamw\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   optimizer_params ............. {'lr': 3e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.01}\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   pld_enabled .................. False\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   pld_params ................... False\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   prescale_gradients ........... False\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   scheduler_name ............... None\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   scheduler_params ............. None\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   sparse_attention ............. None\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   steps_per_print .............. None\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True\n",
      "[2025-05-21 20:35:47,676] [INFO] [config.py:1003:print]   train_batch_size ............. 2\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   use_node_local_storage ....... False\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   weight_quantization_config ... None\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   world_size ................... 2\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   zero_enabled ................. True\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3\n",
      "[2025-05-21 20:35:47,677] [INFO] [config.py:989:print_user_config]   json = {\n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"overlap_comm\": true\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 3e-05, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.01\n",
      "        }\n",
      "    }, \n",
      "    \"replace_with_kernel_inject\": false, \n",
      "    \"enable_cuda_graph\": false\n",
      "}\n",
      "[Rank 1] input_ids.shape: torch.Size([1, 23])\n",
      "[Rank 1] Allocated: 1.00 GB\n",
      "[Rank 1] Reserved:  4.00 GB\n",
      "[Rank 1] model type: <class 'deepspeed.runtime.engine.DeepSpeedEngine'>\n",
      "[Rank 1] has backward: True\n",
      "\n",
      "ðŸ” Running batch size = 1\n",
      "[Rank 0] input_ids.shape: torch.Size([1, 21])\n",
      "[Rank 0] Allocated: 1.00 GB\n",
      "[Rank 0] Reserved:  4.00 GB\n",
      "[Rank 0] model type: <class 'deepspeed.runtime.engine.DeepSpeedEngine'>\n",
      "[Rank 0] has backward: True\n",
      "[2025-05-21 20:35:51,477] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "[2025-05-21 20:35:51,477] [INFO] [stage3.py:2024:_loco_err_buf_update] update loco-zero++ error buffer with overflow: True\n",
      "[2025-05-21 20:35:53,910] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "[2025-05-21 20:35:53,910] [INFO] [stage3.py:2024:_loco_err_buf_update] update loco-zero++ error buffer with overflow: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch=1 | SeqLen=32\n",
      "Elapsed GPU time: 1.5687s | TFLOP/s: 0.1 | AI: 22.85 FLOP/B\n",
      "Batch=1 | SeqLen=32\n",
      "Elapsed GPU time: 1.5746s | TFLOP/s: 0.1 | AI: 22.85 FLOP/B\n",
      "--------- OUTPUT BREAKDOWN ---------\n",
      "ðŸ§  Tokens generated: 64\n",
      "âš¡ Throughput: 40.72200 tokens/sec\n",
      "â±ï¸ Total time: 1.57163 sec\n",
      "ðŸ’¸ Cost per 1M tokens: $8.25380\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import importlib\n",
    "import torch\n",
    "import src.utils.model_utils as mutils\n",
    "importlib.reload(mutils)\n",
    "\n",
    "seq_len = 32\n",
    "min_new_tokens = 1\n",
    "world_size = 2\n",
    "\n",
    "ds_config = {\n",
    "    \"train_micro_batch_size_per_gpu\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "\n",
    "    \"fp16\": { \"enabled\": True },\n",
    "    \n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        # optional perf tweaks:\n",
    "        \"contiguous_gradients\": True,\n",
    "        \"overlap_comm\": True\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 3e-5,\n",
    "            \"betas\": [0.9, 0.999],\n",
    "            \"eps\": 1e-8,\n",
    "            \"weight_decay\": 0.01\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"replace_with_kernel_inject\": False,\n",
    "    \"enable_cuda_graph\": False\n",
    "}\n",
    "\n",
    "\n",
    "results = mutils.run_distributed_benchmark(\n",
    "    model_name=\"NousResearch/Llama-3.2-1B\",\n",
    "    seq_len=32,\n",
    "    batch_sizes=[1],\n",
    "    dtype=torch.bfloat16,\n",
    "    sharding=True,\n",
    "    world_size=world_size, # Number of GPUs\n",
    "    ds_config=ds_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Parallism\n",
    "![](./assets/tp.png)\n",
    "**How it works:**\n",
    "Individual layers are sharded across GPUs â€” e.g., split matrix rows/columns in linear layers. Typically this requires a custom implementation of the model for parallism. This is usually done for popular models by frameworks like Pytorch and Deepspeed, but keep this in mind when using cutting edge models or creating your own, if the architecure is unique the model definition will need to account for this.\n",
    "\n",
    "âœ… Advantages:\n",
    "- Enables sharding of very large models/layers\n",
    "- Reduces per-GPU memory usage\n",
    "- Exploits fine-grained parallelism within layers\n",
    "- Less CC than CC heavy DP\n",
    "- Reduces compute\n",
    "\n",
    "âŒ Disadvantages:\n",
    "- Requires deep model rewrites or tools like DeepSpeed/FSDP\n",
    "- Requires custom communication (e.g., all_gather, reduce_scatter)\n",
    "- CC (e.g., NCCL) can dominate runtime if not optimized or scaled too high\n",
    "\n",
    "> We will stack types of parallism on top of each other as by themselves they may not be enough to to store in memory. For example, we will stack DP and TP in this case. You will see DP, and TP moving forward as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-21 20:56:32,118] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-21 20:56:32,233] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-21 20:56:32,260] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-21 20:56:32,267] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-21 20:56:33,976] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-21 20:56:34,053] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-21 20:56:34,053] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-05-21 20:56:34,198] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-21 20:56:34,222] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-21 20:56:34,714] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4\n",
      "[2025-05-21 20:56:34,759] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4\n",
      "[2025-05-21 20:56:34,812] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4\n",
      "benchmark failed: CPUAdam is not a supported DeepSpeed Optimizer\n",
      "[2025-05-21 20:56:34,894] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.2, git-hash=unknown, git-branch=unknown\n",
      "[2025-05-21 20:56:34,894] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized\n",
      "[2025-05-21 20:56:34,894] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4\n",
      "benchmark failed: CPUAdam is not a supported DeepSpeed Optimizer\n",
      "benchmark failed: CPUAdam is not a supported DeepSpeed Optimizer\n",
      "benchmark failed: CPUAdam is not a supported DeepSpeed Optimizer\n",
      "âŒ Benchmark returned None; skipping.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import importlib\n",
    "import torch\n",
    "import src.utils.model_utils as mutils\n",
    "importlib.reload(mutils)\n",
    "\n",
    "seq_len = 32\n",
    "min_new_tokens = 1\n",
    "world_size = 4\n",
    "\n",
    "ds_config = {\n",
    "  \"train_micro_batch_size_per_gpu\": 1,\n",
    "  \"gradient_accumulation_steps\": 1,\n",
    "\n",
    "  \"fp16\": {\n",
    "    \"enabled\": True\n",
    "  },\n",
    "\n",
    "  \"tensor_parallel\": {\n",
    "    \"enabled\": True,\n",
    "    \"tp_size\": 4\n",
    "  },\n",
    "\n",
    "  ### ISSUE CODE REQUIRES OPTOMIZER FOR SOME REASON FIX\n",
    "  \"optimizer\": {\n",
    "    \"type\": \"CPUAdam\",         \n",
    "    \"params\": {\n",
    "      \"lr\": 3e-5,\n",
    "      \"betas\": [0.9, 0.999],\n",
    "      \"eps\": 1e-8,\n",
    "      \"weight_decay\": 0.01\n",
    "    }\n",
    "  },\n",
    "\n",
    "\n",
    "  \"replace_with_kernel_inject\": True,\n",
    "  \"enable_cuda_graph\": False,\n",
    "\n",
    "  \"wall_clock_breakdown\": False,\n",
    "  \"steps_per_print\": 1000000\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "results = mutils.run_distributed_benchmark(\n",
    "    model_name=\"NousResearch/Llama-3.2-1B\",\n",
    "    seq_len=32,\n",
    "    batch_sizes=[1],\n",
    "    dtype=torch.bfloat16,\n",
    "    sharding=True,\n",
    "    world_size=world_size, # Number of GPUs\n",
    "    ds_config=ds_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Tensor parallism is exactly the same as what we demonstrated in the last lab. This allows us to launch a much larger model by utilizing more GPUs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Parallelism\n",
    "![](./assets/pp.png)\n",
    "**How it works:**\n",
    "Each GPU holds a different stage of the model. Batches are split into micro-batches and passed between GPUs sequentially.\n",
    "\n",
    "âœ… Advantages:\n",
    "Works well for extremely deep models\n",
    "- Spreads compute and memory across GPUs\n",
    "- Compatible with tensor parallelism for hybrid scaling\n",
    "- Reduce CC needed for parallism\n",
    "\n",
    "âŒ Disadvantages:\n",
    "- Latency due to pipeline bubbles (idle GPUs while others compute)\n",
    "- Complex micro-batching & scheduling\n",
    "- Harder to load balance if layers are uneven in cost\n",
    "\n",
    "> Note: We will be using DP as deepspeed defaults, but no TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-16 19:06:59,197] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-16 19:06:59,217] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-16 19:06:59,294] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-16 19:06:59,295] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-16 19:07:01,097] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-16 19:07:01,097] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2025-05-16 19:07:01,249] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=192.168.0.170, master_port=29500\n",
      "[2025-05-16 19:07:01,249] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-05-16 19:07:01,255] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-16 19:07:01,255] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2025-05-16 19:07:01,256] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-16 19:07:01,256] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2025-05-16 19:07:01,268] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-16 19:07:01,268] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2025-05-16 19:07:01,454] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=192.168.0.170, master_port=29500\n",
      "[2025-05-16 19:07:01,454] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-05-16 19:07:01,464] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=192.168.0.170, master_port=29500\n",
      "[2025-05-16 19:07:01,464] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-05-16 19:07:01,474] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=192.168.0.170, master_port=29500\n",
      "[2025-05-16 19:07:01,474] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.98it/s]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.99it/s]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.94it/s]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n",
      "Using topology: {ProcessCoord(pipe=0, data=0): 0, ProcessCoord(pipe=1, data=0): 1, ProcessCoord(pipe=2, data=0): 2, ProcessCoord(pipe=3, data=0): 3}\n",
      "[2025-05-16 19:07:02,119] [INFO] [module.py:396:_partition_layers] Partitioning pipeline stages with method parameters\n",
      "stage=0 layers=1\n",
      "     0: LlamaModel\n",
      "stage=1 layers=1\n",
      "     1: Linear\n",
      "stage=2 layers=0\n",
      "stage=3 layers=0\n",
      "  loss: CrossEntropyLoss\n",
      "[2025-05-16 19:07:02,138] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized\n",
      "[2025-05-16 19:07:02,138] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 1\n",
      "[2025-05-16 19:07:02,187] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized\n",
      "[2025-05-16 19:07:02,188] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 1\n",
      "[2025-05-16 19:07:02,699] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized\n",
      "[2025-05-16 19:07:02,699] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 1\n",
      "[2025-05-16 19:07:04,147] [WARNING] [cpu_adam.py:84:__init__] FP16 params for CPUAdam may not work on AMD CPUs\n",
      "[2025-05-16 19:07:04,577] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.2, git-hash=unknown, git-branch=unknown\n",
      "[2025-05-16 19:07:04,577] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized\n",
      "[2025-05-16 19:07:04,577] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 1\n",
      "[2025-05-16 19:07:04,818] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2025-05-16 19:07:05,951] [WARNING] [cpu_adam.py:84:__init__] FP16 params for CPUAdam may not work on AMD CPUs\n",
      "Installed CUDA version 12.6 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination\n",
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 2.2861506938934326 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000030, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2025-05-16 19:07:06,435] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ec2-user/.cache/torch_extensions/py312_cu124 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ec2-user/.cache/torch_extensions/py312_cu124/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module cpu_adam...\n",
      "[rank1]:[W516 19:07:07.988433556 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark failed: optimizer got an empty parameter list\n",
      "benchmark failed: optimizer got an empty parameter list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function DeepSpeedCPUAdam.__del__ at 0x7fba3c32e200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.12/site-packages/deepspeed/ops/adam/cpu_adam.py\", line 102, in __del__\n",
      "    self.ds_opt_adam.destroy_adam(self.opt_id)\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DeepSpeedCPUAdam' object has no attribute 'ds_opt_adam'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/synchronize.py\", line 87, in _cleanup\n",
      "    sem_unlink(name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Exception ignored in: <function DeepSpeedCPUAdam.__del__ at 0x7f20c8e32200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.12/site-packages/deepspeed/ops/adam/cpu_adam.py\", line 102, in __del__\n",
      "    self.ds_opt_adam.destroy_adam(self.opt_id)\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DeepSpeedCPUAdam' object has no attribute 'ds_opt_adam'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/synchronize.py\", line 87, in _cleanup\n",
      "    sem_unlink(name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "[ip-192-168-0-170.ec2.internal:1136099] [[15837,1],0] ORTE_ERROR_LOG: Unreachable in file runtime/ompi_mpi_finalize.c at line 262\n",
      "[ip-192-168-0-170.ec2.internal:1136100] [[15838,1],0] ORTE_ERROR_LOG: Unreachable in file runtime/ompi_mpi_finalize.c at line 262\n",
      "Using /home/ec2-user/.cache/torch_extensions/py312_cu124 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/ec2-user/.cache/torch_extensions/py312_cu124/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed CUDA version 12.6 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination\n",
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 2.288069725036621 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000030, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2025-05-16 19:07:08,240] [INFO] [logging.py:128:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2025-05-16 19:07:08,240] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-05-16 19:07:08,247] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2025-05-16 19:07:08,247] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2025-05-16 19:07:08,247] [INFO] [logging.py:128:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2025-05-16 19:07:08,247] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2025-05-16 19:07:08,371] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning\n",
      "[2025-05-16 19:07:08,372] [INFO] [utils.py:782:see_memory_usage] MA 13.98 GB         Max_MA 14.96 GB         CA 15.08 GB         Max_CA 15 GB \n",
      "[2025-05-16 19:07:08,372] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 10.77 GB, percent = 5.9%\n",
      "[2025-05-16 19:07:08,373] [INFO] [stage3.py:168:__init__] Reduce bucket size 500000000\n",
      "[2025-05-16 19:07:08,373] [INFO] [stage3.py:169:__init__] Prefetch bucket size 50000000\n",
      "[2025-05-16 19:07:08,482] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2025-05-16 19:07:08,483] [INFO] [utils.py:782:see_memory_usage] MA 13.98 GB         Max_MA 13.98 GB         CA 15.08 GB         Max_CA 15 GB \n",
      "[2025-05-16 19:07:08,483] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 10.77 GB, percent = 5.9%\n",
      "[2025-05-16 19:07:08,485] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 1\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2025-05-16 19:07:17,885] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2025-05-16 19:07:17,885] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 13.98 GB         CA 15.08 GB         Max_CA 15 GB \n",
      "[2025-05-16 19:07:17,885] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.57 GB, percent = 14.1%\n",
      "[2025-05-16 19:07:17,997] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions\n",
      "[2025-05-16 19:07:17,997] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 15.08 GB         Max_CA 15 GB \n",
      "[2025-05-16 19:07:17,998] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.57 GB, percent = 14.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W516 19:07:17.938833174 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     10\u001b[39m max_tokens =  seq_len + min_new_tokens\n\u001b[32m     12\u001b[39m ds_config = {\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrain_micro_batch_size_per_gpu\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgradient_accumulation_steps\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33menable_cuda_graph\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     65\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m results = \u001b[43mmutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_distributed_benchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNousResearch/Meta-Llama-3.1-8B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43msharding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Number of GPUs\u001b[39;49;00m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mds_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_config\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environment/src/utils/model_utils.py:447\u001b[39m, in \u001b[36mrun_distributed_benchmark\u001b[39m\u001b[34m(model_name, seq_len, batch_sizes, dtype, sharding, world_size, ds_config)\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Manager() \u001b[38;5;28;01mas\u001b[39;00m manager:\n\u001b[32m    445\u001b[39m     shared_results = manager.list()\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[43mmp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_distributed_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m            \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m            \u001b[49m\u001b[43msharding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m            \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m            \u001b[49m\u001b[43mds_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshared_results\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(shared_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:340\u001b[39m, in \u001b[36mspawn\u001b[39m\u001b[34m(fn, args, nprocs, join, daemon, start_method)\u001b[39m\n\u001b[32m    334\u001b[39m     msg = (\n\u001b[32m    335\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    336\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    337\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    338\u001b[39m     )\n\u001b[32m    339\u001b[39m     warnings.warn(msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspawn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:296\u001b[39m, in \u001b[36mstart_processes\u001b[39m\u001b[34m(fn, args, nprocs, join, daemon, start_method)\u001b[39m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    297\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:144\u001b[39m, in \u001b[36mProcessContext.join\u001b[39m\u001b[34m(self, timeout, grace_period)\u001b[39m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m ready = \u001b[43mmultiprocessing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msentinels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m error_index = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentinel \u001b[38;5;129;01min\u001b[39;00m ready:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/multiprocessing/connection.py:1136\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1133\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import importlib\n",
    "import torch\n",
    "import src.utils.model_utils as mutils\n",
    "importlib.reload(mutils)\n",
    "\n",
    "seq_len = 32\n",
    "world_size = 4\n",
    "\n",
    "ds_config = {\n",
    "    \"train_micro_batch_size_per_gpu\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "\n",
    "    \"fp16\": { \"enabled\": True },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1,\n",
    "        \"contiguous_gradients\": True,\n",
    "        \"overlap_comm\": True\n",
    "    },\n",
    "\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 3e-5,\n",
    "            \"betas\": [0.9, 0.999],\n",
    "            \"eps\": 1e-8,\n",
    "            \"weight_decay\": 0.01\n",
    "        }\n",
    "    }, # Ignore this for now\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        # optional perf tweaks:\n",
    "        \"contiguous_gradients\": True,\n",
    "        \"overlap_comm\": True\n",
    "    },\n",
    "    \n",
    "    # Splitting the model across 4 GPUs\n",
    "    \"tensor_parallel\": {\n",
    "        \"enabled\": True,\n",
    "        \"tp_size\": world_size\n",
    "    },\n",
    "\n",
    "    # pipeline parallel: split layers\n",
    "    \"pipeline\": {\n",
    "        \"enabled\": True,\n",
    "        \"stages\": 4,                # 2 pipeline stages Ã— 2-way TP Ã— 2-way DP = 4 GPUs\n",
    "        \"partition_method\": \"parameters\",\n",
    "        \"activation_checkpoint_interval\": 1\n",
    "    },\n",
    "\n",
    "    \"replace_with_kernel_inject\": False,\n",
    "    \"enable_cuda_graph\": False\n",
    "}\n",
    "\n",
    "results = mutils.run_distributed_benchmark(\n",
    "    model_name=\"NousResearch/Meta-Llama-3.1-8B\",\n",
    "    seq_len=32,\n",
    "    batch_sizes=[1],\n",
    "    dtype=torch.bfloat16,\n",
    "    sharding=True,\n",
    "    world_size=world_size, # Number of GPUs\n",
    "    ds_config=ds_config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
